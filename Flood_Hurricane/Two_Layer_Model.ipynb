{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns which I think are not useful or hard to utilize: \n",
    "\n",
    "- year: Storm year\n",
    "- county: Impacted county name\n",
    "- abrState: State postal abreviation\n",
    "- name: Storm name\n",
    "- numInMonth: Storm sequence in storm's month 1 (all 1's)\n",
    "- numInSeason: Storm sequence in storm's season (all 1's)\n",
    "- recoverCount: Storm sequence in previous storm's recovery period (all 1's)\n",
    "- takeupTotal: County take up rate in month 0\n",
    "\n",
    "### One-hot encoding variables: \n",
    "\n",
    "- month: Storm month\n",
    "- CAT: Storm category over county"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = pd.read_csv('sampleUnstr.csv')\n",
    "\n",
    "# Drop columns mentioned above\n",
    "raw.drop(['year','county','abrState','name','numInMonth', 'numInSeason','recoverCount','takeupTotal'], axis=1, inplace=True)\n",
    "\n",
    "# One-hot encoding\n",
    "dummy_month = pd.get_dummies(raw.month)\n",
    "dummy_CAT = pd.get_dummies(raw.CAT)\n",
    "data = pd.concat([raw, dummy_month, dummy_CAT], axis=1, sort=False)\n",
    "data.drop(['month','CAT'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([           'recovery',            'prevProd',          'Production',\n",
       "                      'vmax',                'mslp',                'time',\n",
       "               'ratePoverty',    'houseMedianValue',       'houseOccupied',\n",
       "                'houseTotal', 'sumBuildingCoverage',         'policyCount',\n",
       "                           1,                     2,                     3,\n",
       "                           4,                     5,                     6,\n",
       "                           7,                     8,                     9,\n",
       "                          10,                    11,                    12,\n",
       "                        'EX',                  'H1',                  'H2',\n",
       "                        'H3',                  'H4',                  'H5',\n",
       "                        'LO',                  'SS',                  'TD',\n",
       "                        'TS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models \n",
    "\n",
    "2-layer model framework: <br>\n",
    "  First layer: classification for whether obs is an outlier (set threshold = 12, minority class ratio = 10%) <br>\n",
    "  Second layer: regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train valid test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def outlier_label(df, i, threshold):\n",
    "    if df.iloc[i].recovery > threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['greater_2'] = [outlier_label(data, i, 2) for i in range(len(data))]\n",
    "data['outlier'] = [outlier_label(data, i, 11) for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data.drop(['recovery'], axis=1), data[['recovery', 'outlier', 'greater_2']]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([           'prevProd',          'Production',                'vmax',\n",
       "                      'mslp',                'time',         'ratePoverty',\n",
       "          'houseMedianValue',       'houseOccupied',          'houseTotal',\n",
       "       'sumBuildingCoverage',         'policyCount',                     1,\n",
       "                           2,                     3,                     4,\n",
       "                           5,                     6,                     7,\n",
       "                           8,                     9,                    10,\n",
       "                          11,                    12,                  'EX',\n",
       "                        'H1',                  'H2',                  'H3',\n",
       "                        'H4',                  'H5',                  'LO',\n",
       "                        'SS',                  'TD',                  'TS',\n",
       "                 'greater_2',             'outlier'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st layer (a): classification random forest for recovery = 2\n",
    "\n",
    "Output model name: **layer1a_rf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.84      0.91        95\n",
      "           1       0.96      1.00      0.98       395\n",
      "\n",
      "    accuracy                           0.97       490\n",
      "   macro avg       0.98      0.92      0.95       490\n",
      "weighted avg       0.97      0.97      0.97       490\n",
      "\n",
      "F1 score: 0.9813664596273292\n",
      "AUC: 0.9987608261159227\n",
      "Accuracy: 0.9693877551020408\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X_train_1 = X_train.drop(['outlier', 'greater_2'], axis=1)\n",
    "y_train_1 = X_train['greater_2']\n",
    "X_test_1 = X_test.drop(['outlier', 'greater_2'], axis=1)\n",
    "y_test_1 = X_test['greater_2']\n",
    "\n",
    "parameters = {'n_estimators':[50,100], 'max_depth':[None, 5, 10]}\n",
    "layer1a_rf = GridSearchCV(RandomForestClassifier(random_state=1, oob_score=True, class_weight='balanced_subsample'), parameters, scoring='f1')\n",
    "layer1a_rf.fit(X_train_1, y_train_1)\n",
    "\n",
    "y_pred_rf = layer1a_rf.predict(X_test_1)\n",
    "y_pred_proba_rf = layer1a_rf.predict_proba(X_test_1)[::,1]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test_1, y_pred_proba_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "print(classification_report(y_test_1, y_pred_rf))\n",
    "print('F1 score:', f1_score(y_test_1,y_pred_rf))\n",
    "print('AUC:', auc_rf)\n",
    "print('Accuracy:', accuracy_score(y_test_1,y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st layer (b): classification random forest for outlier (recovery >= 12)\n",
    "\n",
    "Output model name: **layer1b_rf**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       157\n",
      "           1       1.00      1.00      1.00       238\n",
      "\n",
      "    accuracy                           1.00       395\n",
      "   macro avg       1.00      1.00      1.00       395\n",
      "weighted avg       1.00      1.00      1.00       395\n",
      "\n",
      "F1 score: 1.0\n",
      "AUC: 1.0\n",
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "X_train_1b = X_train[X_train.greater_2 == 1].drop(['outlier', 'greater_2'], axis=1)\n",
    "y_train_1b = X_train[X_train.greater_2 == 1]['outlier']\n",
    "X_test_1b = X_test[X_test.greater_2 == 1].drop(['outlier', 'greater_2'], axis=1)\n",
    "y_test_1b = X_test[X_test.greater_2 == 1]['outlier']\n",
    "\n",
    "parameters = {'n_estimators':[50,100], 'max_depth':[None, 5, 10]}\n",
    "layer1b_rf = GridSearchCV(RandomForestClassifier(random_state=1, oob_score=True, class_weight='balanced_subsample'), parameters, scoring='f1')\n",
    "layer1b_rf.fit(X_train_1b, y_train_1b)\n",
    "\n",
    "y_pred_rf = layer1b_rf.predict(X_test_1b)\n",
    "y_pred_proba_rf = layer1b_rf.predict_proba(X_test_1b)[::,1]\n",
    "fpr_rf, tpr_rf, thresholds_rf = roc_curve(y_test_1b, y_pred_proba_rf)\n",
    "auc_rf = auc(fpr_rf, tpr_rf)\n",
    "\n",
    "print(classification_report(y_test_1b, y_pred_rf))\n",
    "print('F1 score:', f1_score(y_test_1b, y_pred_rf))\n",
    "print('AUC:', auc_rf)\n",
    "print('Accuracy:', accuracy_score(y_test_1b,y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second layer (a): non-outliers (recovery in [3,11])\n",
    "\n",
    "Decision Tree Regression, Random Forest Regression, Gradient Boosting Regression <br>\n",
    "All conducted on 5 folds cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuweiwang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n",
      "/Users/yuweiwang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree R2: 0.5512940608247604\n",
      "Random Forest R2: 0.6251368332850928\n",
      "Gradient Boosting R2: 0.806763200980084\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "X_train_2a = X_train[X_train['outlier']==0][X_train['greater_2']==1]\n",
    "y_train_2a = y_train[y_train['outlier']==0][y_train['greater_2']==1]['recovery']\n",
    "X_train_2a.drop(['outlier', 'greater_2'], axis=1, inplace=True)\n",
    "\n",
    "# DT\n",
    "layer2a_dt = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "print('Decision Tree R2:', cross_val_score(layer2a_dt, X_train_2a, y_train_2a, scoring='r2').mean())\n",
    "\n",
    "# RF\n",
    "layer2a_rf = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "print('Random Forest R2:', cross_val_score(layer2a_rf, X_train_2a, y_train_2a, scoring='r2').mean())\n",
    "\n",
    "# GB\n",
    "layer2a_gb = GradientBoostingRegressor(random_state=0)\n",
    "print('Gradient Boosting R2:', cross_val_score(layer2a_gb, X_train_2a, y_train_2a, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second layer (b): outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuweiwang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree R2: 0.9911196355046821\n",
      "Random Forest R2: 0.9938149799229089\n",
      "Gradient Boosting R2: 0.9993397764999965\n"
     ]
    }
   ],
   "source": [
    "X_train_2b = X_train[X_train['outlier']==1][X_train['greater_2']==1]\n",
    "y_train_2b = y_train[y_train['outlier']==1]['recovery']\n",
    "X_train_2b.drop(['outlier', 'greater_2'], axis=1, inplace=True)\n",
    "\n",
    "# DT\n",
    "layer2b_dt = DecisionTreeRegressor(max_depth=5, random_state=0)\n",
    "print('Decision Tree R2:', cross_val_score(layer2b_dt, X_train_2b, y_train_2b, scoring='r2').mean())\n",
    "\n",
    "# RF\n",
    "layer2b_rf = RandomForestRegressor(max_depth=5, random_state=0)\n",
    "print('Random Forest R2:', cross_val_score(layer2b_rf, X_train_2b, y_train_2b, scoring='r2').mean())\n",
    "\n",
    "# GB\n",
    "layer2b_gb = GradientBoostingRegressor(random_state=0)\n",
    "print('Gradient Boosting R2:', cross_val_score(layer2b_gb, X_train_2b, y_train_2b, scoring='r2').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuweiwang/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "X_test.drop(['outlier', 'greater_2'], axis=1, inplace=True)\n",
    "y_test.drop(['outlier', 'greater_2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(X_test, greater2_ind, outlier_ind):\n",
    "    '''\n",
    "    The logic is as follows: we first predict all observations with both layer-2 models. \n",
    "                             then depends on output of layer-1 classifications, append values accordingly\n",
    "    For 2nd layer: 2(a) use gradient boosting, 2(b) use random forest\n",
    "    '''\n",
    "    y_pred = []\n",
    "    \n",
    "    layer2a_gb.fit(X_train_2a, y_train_2a)\n",
    "    y_pred_a = layer2a_gb.predict(X_test)\n",
    "    \n",
    "    layer2b_rf.fit(X_train_2b, y_train_2b)\n",
    "    y_pred_b = layer2b_rf.predict(X_test)\n",
    "    \n",
    "    for i in range(len(X_test)):\n",
    "        if greater2_ind[i] == 0:\n",
    "            y_pred.append(2)\n",
    "        elif outlier_ind[i] == 0:\n",
    "            y_pred.append(y_pred_a[i])\n",
    "        elif outlier_ind[i] == 1:\n",
    "            y_pred.append(y_pred_b[i])\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test R2 score: 0.9927730324038248\n",
      "Test MSE: 6.463153273812686\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "greater2_pred = layer1a_rf.predict(X_test)\n",
    "outlier_pred = layer1b_rf.predict(X_test)\n",
    "y_pred = prediction(X_test, greater2_pred, outlier_pred)\n",
    "\n",
    "print('Test R2 score:', r2_score(y_test,y_pred))\n",
    "print('Test MSE:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison with single layer regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuweiwang/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Layer R2 score: 0.9293522567472512\n",
      "Single Layer MSE: 63.18102122571221\n"
     ]
    }
   ],
   "source": [
    "X_train_single = X_train.drop(['outlier','greater_2'], axis=1)\n",
    "y_train_single = y_train.drop(['outlier','greater_2'], axis=1)\n",
    "\n",
    "single_rf = RandomForestRegressor(random_state=1, max_depth=5)\n",
    "single_rf.fit(X_train_single, y_train_single)\n",
    "y_pred_single = single_rf.predict(X_test)\n",
    "\n",
    "print('Single Layer R2 score:', r2_score(y_test,y_pred_single))\n",
    "print('Single Layer MSE:', mean_squared_error(y_test, y_pred_single))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
